global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'codelab-monitor'

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
# - "first.rules"
# - "second.rules"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'java-simple'
    metrics_path: '/actuator/prometheus'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
#      - targets: ['host.docker.internal:8080'] #for host machine address IP to find app server
      - targets: ['java-simple:8080']


#  - job_name: docker
#      # metrics_path defaults to '/metrics'
#    # scheme defaults to 'http'.
#
#    static_configs:
#      - targets: ["host.docker.internal:9323"]

# The --add-host flag is optional. This flag makes sure that the host's internal IP gets exposed to the Prometheus container. Docker Desktop does this by default. The host IP is exposed as the host.docker.internal hostname.
